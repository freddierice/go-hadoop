// Code generated by protoc-gen-go.
// source: ClientDatanodeProtocol.proto
// DO NOT EDIT!

/*
Package client is a generated protocol buffer package.

It is generated from these files:
	ClientDatanodeProtocol.proto

It has these top-level messages:
	GetReplicaVisibleLengthRequestProto
	GetReplicaVisibleLengthResponseProto
	RefreshNamenodesRequestProto
	RefreshNamenodesResponseProto
	DeleteBlockPoolRequestProto
	DeleteBlockPoolResponseProto
	GetBlockLocalPathInfoRequestProto
	GetBlockLocalPathInfoResponseProto
	ShutdownDatanodeRequestProto
	ShutdownDatanodeResponseProto
	EvictWritersRequestProto
	EvictWritersResponseProto
	GetDatanodeInfoRequestProto
	GetDatanodeInfoResponseProto
	TriggerBlockReportRequestProto
	TriggerBlockReportResponseProto
	GetBalancerBandwidthRequestProto
	GetBalancerBandwidthResponseProto
	SubmitDiskBalancerPlanRequestProto
	SubmitDiskBalancerPlanResponseProto
	CancelPlanRequestProto
	CancelPlanResponseProto
	QueryPlanStatusRequestProto
	QueryPlanStatusResponseProto
	DiskBalancerSettingRequestProto
	DiskBalancerSettingResponseProto
*/
package client

import proto "github.com/golang/protobuf/proto"
import fmt "fmt"
import math "math"
import hadoop_common "."
import hadoop_hdfs "."
import hadoop_hdfs1 "."

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package

// *
// block - block for which visible length is requested
type GetReplicaVisibleLengthRequestProto struct {
	Block            *hadoop_hdfs.ExtendedBlockProto `protobuf:"bytes,1,req,name=block" json:"block,omitempty"`
	XXX_unrecognized []byte                          `json:"-"`
}

func (m *GetReplicaVisibleLengthRequestProto) Reset()         { *m = GetReplicaVisibleLengthRequestProto{} }
func (m *GetReplicaVisibleLengthRequestProto) String() string { return proto.CompactTextString(m) }
func (*GetReplicaVisibleLengthRequestProto) ProtoMessage()    {}
func (*GetReplicaVisibleLengthRequestProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{0}
}

func (m *GetReplicaVisibleLengthRequestProto) GetBlock() *hadoop_hdfs.ExtendedBlockProto {
	if m != nil {
		return m.Block
	}
	return nil
}

// *
// length - visible length of the block
type GetReplicaVisibleLengthResponseProto struct {
	Length           *uint64 `protobuf:"varint,1,req,name=length" json:"length,omitempty"`
	XXX_unrecognized []byte  `json:"-"`
}

func (m *GetReplicaVisibleLengthResponseProto) Reset()         { *m = GetReplicaVisibleLengthResponseProto{} }
func (m *GetReplicaVisibleLengthResponseProto) String() string { return proto.CompactTextString(m) }
func (*GetReplicaVisibleLengthResponseProto) ProtoMessage()    {}
func (*GetReplicaVisibleLengthResponseProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{1}
}

func (m *GetReplicaVisibleLengthResponseProto) GetLength() uint64 {
	if m != nil && m.Length != nil {
		return *m.Length
	}
	return 0
}

// *
// void request
type RefreshNamenodesRequestProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *RefreshNamenodesRequestProto) Reset()                    { *m = RefreshNamenodesRequestProto{} }
func (m *RefreshNamenodesRequestProto) String() string            { return proto.CompactTextString(m) }
func (*RefreshNamenodesRequestProto) ProtoMessage()               {}
func (*RefreshNamenodesRequestProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{2} }

// *
// void response
type RefreshNamenodesResponseProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *RefreshNamenodesResponseProto) Reset()                    { *m = RefreshNamenodesResponseProto{} }
func (m *RefreshNamenodesResponseProto) String() string            { return proto.CompactTextString(m) }
func (*RefreshNamenodesResponseProto) ProtoMessage()               {}
func (*RefreshNamenodesResponseProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{3} }

// *
// blockPool - block pool to be deleted
// force - if false, delete the block pool only if it is empty.
//         if true, delete the block pool even if it has blocks.
type DeleteBlockPoolRequestProto struct {
	BlockPool        *string `protobuf:"bytes,1,req,name=blockPool" json:"blockPool,omitempty"`
	Force            *bool   `protobuf:"varint,2,req,name=force" json:"force,omitempty"`
	XXX_unrecognized []byte  `json:"-"`
}

func (m *DeleteBlockPoolRequestProto) Reset()                    { *m = DeleteBlockPoolRequestProto{} }
func (m *DeleteBlockPoolRequestProto) String() string            { return proto.CompactTextString(m) }
func (*DeleteBlockPoolRequestProto) ProtoMessage()               {}
func (*DeleteBlockPoolRequestProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{4} }

func (m *DeleteBlockPoolRequestProto) GetBlockPool() string {
	if m != nil && m.BlockPool != nil {
		return *m.BlockPool
	}
	return ""
}

func (m *DeleteBlockPoolRequestProto) GetForce() bool {
	if m != nil && m.Force != nil {
		return *m.Force
	}
	return false
}

// *
// void response
type DeleteBlockPoolResponseProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *DeleteBlockPoolResponseProto) Reset()                    { *m = DeleteBlockPoolResponseProto{} }
func (m *DeleteBlockPoolResponseProto) String() string            { return proto.CompactTextString(m) }
func (*DeleteBlockPoolResponseProto) ProtoMessage()               {}
func (*DeleteBlockPoolResponseProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{5} }

// *
// Gets the file information where block and its metadata is stored
// block - block for which path information is being requested
// token - block token
//
// This message is deprecated in favor of file descriptor passing.
type GetBlockLocalPathInfoRequestProto struct {
	Block            *hadoop_hdfs.ExtendedBlockProto `protobuf:"bytes,1,req,name=block" json:"block,omitempty"`
	Token            *hadoop_common.TokenProto       `protobuf:"bytes,2,req,name=token" json:"token,omitempty"`
	XXX_unrecognized []byte                          `json:"-"`
}

func (m *GetBlockLocalPathInfoRequestProto) Reset()         { *m = GetBlockLocalPathInfoRequestProto{} }
func (m *GetBlockLocalPathInfoRequestProto) String() string { return proto.CompactTextString(m) }
func (*GetBlockLocalPathInfoRequestProto) ProtoMessage()    {}
func (*GetBlockLocalPathInfoRequestProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{6}
}

func (m *GetBlockLocalPathInfoRequestProto) GetBlock() *hadoop_hdfs.ExtendedBlockProto {
	if m != nil {
		return m.Block
	}
	return nil
}

func (m *GetBlockLocalPathInfoRequestProto) GetToken() *hadoop_common.TokenProto {
	if m != nil {
		return m.Token
	}
	return nil
}

// *
// block - block for which file path information is being returned
// localPath - file path where the block data is stored
// localMetaPath - file path where the block meta data is stored
//
// This message is deprecated in favor of file descriptor passing.
type GetBlockLocalPathInfoResponseProto struct {
	Block            *hadoop_hdfs.ExtendedBlockProto `protobuf:"bytes,1,req,name=block" json:"block,omitempty"`
	LocalPath        *string                         `protobuf:"bytes,2,req,name=localPath" json:"localPath,omitempty"`
	LocalMetaPath    *string                         `protobuf:"bytes,3,req,name=localMetaPath" json:"localMetaPath,omitempty"`
	XXX_unrecognized []byte                          `json:"-"`
}

func (m *GetBlockLocalPathInfoResponseProto) Reset()         { *m = GetBlockLocalPathInfoResponseProto{} }
func (m *GetBlockLocalPathInfoResponseProto) String() string { return proto.CompactTextString(m) }
func (*GetBlockLocalPathInfoResponseProto) ProtoMessage()    {}
func (*GetBlockLocalPathInfoResponseProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{7}
}

func (m *GetBlockLocalPathInfoResponseProto) GetBlock() *hadoop_hdfs.ExtendedBlockProto {
	if m != nil {
		return m.Block
	}
	return nil
}

func (m *GetBlockLocalPathInfoResponseProto) GetLocalPath() string {
	if m != nil && m.LocalPath != nil {
		return *m.LocalPath
	}
	return ""
}

func (m *GetBlockLocalPathInfoResponseProto) GetLocalMetaPath() string {
	if m != nil && m.LocalMetaPath != nil {
		return *m.LocalMetaPath
	}
	return ""
}

// *
// forUpgrade - if true, clients are advised to wait for restart and quick
//              upgrade restart is instrumented. Otherwise, datanode does
//              the regular shutdown.
type ShutdownDatanodeRequestProto struct {
	ForUpgrade       *bool  `protobuf:"varint,1,req,name=forUpgrade" json:"forUpgrade,omitempty"`
	XXX_unrecognized []byte `json:"-"`
}

func (m *ShutdownDatanodeRequestProto) Reset()                    { *m = ShutdownDatanodeRequestProto{} }
func (m *ShutdownDatanodeRequestProto) String() string            { return proto.CompactTextString(m) }
func (*ShutdownDatanodeRequestProto) ProtoMessage()               {}
func (*ShutdownDatanodeRequestProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{8} }

func (m *ShutdownDatanodeRequestProto) GetForUpgrade() bool {
	if m != nil && m.ForUpgrade != nil {
		return *m.ForUpgrade
	}
	return false
}

type ShutdownDatanodeResponseProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *ShutdownDatanodeResponseProto) Reset()                    { *m = ShutdownDatanodeResponseProto{} }
func (m *ShutdownDatanodeResponseProto) String() string            { return proto.CompactTextString(m) }
func (*ShutdownDatanodeResponseProto) ProtoMessage()               {}
func (*ShutdownDatanodeResponseProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{9} }

// * Tell datanode to evict active clients that are writing
type EvictWritersRequestProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *EvictWritersRequestProto) Reset()                    { *m = EvictWritersRequestProto{} }
func (m *EvictWritersRequestProto) String() string            { return proto.CompactTextString(m) }
func (*EvictWritersRequestProto) ProtoMessage()               {}
func (*EvictWritersRequestProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{10} }

type EvictWritersResponseProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *EvictWritersResponseProto) Reset()                    { *m = EvictWritersResponseProto{} }
func (m *EvictWritersResponseProto) String() string            { return proto.CompactTextString(m) }
func (*EvictWritersResponseProto) ProtoMessage()               {}
func (*EvictWritersResponseProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{11} }

// *
// Ping datanode for liveness and quick info
type GetDatanodeInfoRequestProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *GetDatanodeInfoRequestProto) Reset()                    { *m = GetDatanodeInfoRequestProto{} }
func (m *GetDatanodeInfoRequestProto) String() string            { return proto.CompactTextString(m) }
func (*GetDatanodeInfoRequestProto) ProtoMessage()               {}
func (*GetDatanodeInfoRequestProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{12} }

type GetDatanodeInfoResponseProto struct {
	LocalInfo        *hadoop_hdfs.DatanodeLocalInfoProto `protobuf:"bytes,1,req,name=localInfo" json:"localInfo,omitempty"`
	XXX_unrecognized []byte                              `json:"-"`
}

func (m *GetDatanodeInfoResponseProto) Reset()                    { *m = GetDatanodeInfoResponseProto{} }
func (m *GetDatanodeInfoResponseProto) String() string            { return proto.CompactTextString(m) }
func (*GetDatanodeInfoResponseProto) ProtoMessage()               {}
func (*GetDatanodeInfoResponseProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{13} }

func (m *GetDatanodeInfoResponseProto) GetLocalInfo() *hadoop_hdfs.DatanodeLocalInfoProto {
	if m != nil {
		return m.LocalInfo
	}
	return nil
}

type TriggerBlockReportRequestProto struct {
	Incremental      *bool  `protobuf:"varint,1,req,name=incremental" json:"incremental,omitempty"`
	XXX_unrecognized []byte `json:"-"`
}

func (m *TriggerBlockReportRequestProto) Reset()                    { *m = TriggerBlockReportRequestProto{} }
func (m *TriggerBlockReportRequestProto) String() string            { return proto.CompactTextString(m) }
func (*TriggerBlockReportRequestProto) ProtoMessage()               {}
func (*TriggerBlockReportRequestProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{14} }

func (m *TriggerBlockReportRequestProto) GetIncremental() bool {
	if m != nil && m.Incremental != nil {
		return *m.Incremental
	}
	return false
}

type TriggerBlockReportResponseProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *TriggerBlockReportResponseProto) Reset()         { *m = TriggerBlockReportResponseProto{} }
func (m *TriggerBlockReportResponseProto) String() string { return proto.CompactTextString(m) }
func (*TriggerBlockReportResponseProto) ProtoMessage()    {}
func (*TriggerBlockReportResponseProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{15}
}

type GetBalancerBandwidthRequestProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *GetBalancerBandwidthRequestProto) Reset()         { *m = GetBalancerBandwidthRequestProto{} }
func (m *GetBalancerBandwidthRequestProto) String() string { return proto.CompactTextString(m) }
func (*GetBalancerBandwidthRequestProto) ProtoMessage()    {}
func (*GetBalancerBandwidthRequestProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{16}
}

// *
// bandwidth - balancer bandwidth value of the datanode.
type GetBalancerBandwidthResponseProto struct {
	Bandwidth        *uint64 `protobuf:"varint,1,req,name=bandwidth" json:"bandwidth,omitempty"`
	XXX_unrecognized []byte  `json:"-"`
}

func (m *GetBalancerBandwidthResponseProto) Reset()         { *m = GetBalancerBandwidthResponseProto{} }
func (m *GetBalancerBandwidthResponseProto) String() string { return proto.CompactTextString(m) }
func (*GetBalancerBandwidthResponseProto) ProtoMessage()    {}
func (*GetBalancerBandwidthResponseProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{17}
}

func (m *GetBalancerBandwidthResponseProto) GetBandwidth() uint64 {
	if m != nil && m.Bandwidth != nil {
		return *m.Bandwidth
	}
	return 0
}

// *
// This message allows a client to submit a disk
// balancer plan to a data node.
type SubmitDiskBalancerPlanRequestProto struct {
	PlanID           *string `protobuf:"bytes,1,req,name=planID" json:"planID,omitempty"`
	Plan             *string `protobuf:"bytes,2,req,name=plan" json:"plan,omitempty"`
	PlanVersion      *uint64 `protobuf:"varint,3,opt,name=planVersion" json:"planVersion,omitempty"`
	IgnoreDateCheck  *bool   `protobuf:"varint,4,opt,name=ignoreDateCheck" json:"ignoreDateCheck,omitempty"`
	XXX_unrecognized []byte  `json:"-"`
}

func (m *SubmitDiskBalancerPlanRequestProto) Reset()         { *m = SubmitDiskBalancerPlanRequestProto{} }
func (m *SubmitDiskBalancerPlanRequestProto) String() string { return proto.CompactTextString(m) }
func (*SubmitDiskBalancerPlanRequestProto) ProtoMessage()    {}
func (*SubmitDiskBalancerPlanRequestProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{18}
}

func (m *SubmitDiskBalancerPlanRequestProto) GetPlanID() string {
	if m != nil && m.PlanID != nil {
		return *m.PlanID
	}
	return ""
}

func (m *SubmitDiskBalancerPlanRequestProto) GetPlan() string {
	if m != nil && m.Plan != nil {
		return *m.Plan
	}
	return ""
}

func (m *SubmitDiskBalancerPlanRequestProto) GetPlanVersion() uint64 {
	if m != nil && m.PlanVersion != nil {
		return *m.PlanVersion
	}
	return 0
}

func (m *SubmitDiskBalancerPlanRequestProto) GetIgnoreDateCheck() bool {
	if m != nil && m.IgnoreDateCheck != nil {
		return *m.IgnoreDateCheck
	}
	return false
}

// *
// Response from the DataNode on Plan Submit request
type SubmitDiskBalancerPlanResponseProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *SubmitDiskBalancerPlanResponseProto) Reset()         { *m = SubmitDiskBalancerPlanResponseProto{} }
func (m *SubmitDiskBalancerPlanResponseProto) String() string { return proto.CompactTextString(m) }
func (*SubmitDiskBalancerPlanResponseProto) ProtoMessage()    {}
func (*SubmitDiskBalancerPlanResponseProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{19}
}

// *
// This message describes a request to cancel an
// outstanding disk balancer plan
type CancelPlanRequestProto struct {
	PlanID           *string `protobuf:"bytes,1,req,name=planID" json:"planID,omitempty"`
	XXX_unrecognized []byte  `json:"-"`
}

func (m *CancelPlanRequestProto) Reset()                    { *m = CancelPlanRequestProto{} }
func (m *CancelPlanRequestProto) String() string            { return proto.CompactTextString(m) }
func (*CancelPlanRequestProto) ProtoMessage()               {}
func (*CancelPlanRequestProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{20} }

func (m *CancelPlanRequestProto) GetPlanID() string {
	if m != nil && m.PlanID != nil {
		return *m.PlanID
	}
	return ""
}

// *
// This is the response for the cancellation request
type CancelPlanResponseProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *CancelPlanResponseProto) Reset()                    { *m = CancelPlanResponseProto{} }
func (m *CancelPlanResponseProto) String() string            { return proto.CompactTextString(m) }
func (*CancelPlanResponseProto) ProtoMessage()               {}
func (*CancelPlanResponseProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{21} }

// *
// This message allows a client to query data node to see
// if a disk balancer plan is executing and if so what is
// the status.
type QueryPlanStatusRequestProto struct {
	XXX_unrecognized []byte `json:"-"`
}

func (m *QueryPlanStatusRequestProto) Reset()                    { *m = QueryPlanStatusRequestProto{} }
func (m *QueryPlanStatusRequestProto) String() string            { return proto.CompactTextString(m) }
func (*QueryPlanStatusRequestProto) ProtoMessage()               {}
func (*QueryPlanStatusRequestProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{22} }

// *
// This message describes a plan if it is in progress
type QueryPlanStatusResponseProto struct {
	Result           *uint32 `protobuf:"varint,1,opt,name=result" json:"result,omitempty"`
	PlanID           *string `protobuf:"bytes,2,opt,name=planID" json:"planID,omitempty"`
	CurrentStatus    *string `protobuf:"bytes,3,opt,name=currentStatus" json:"currentStatus,omitempty"`
	XXX_unrecognized []byte  `json:"-"`
}

func (m *QueryPlanStatusResponseProto) Reset()                    { *m = QueryPlanStatusResponseProto{} }
func (m *QueryPlanStatusResponseProto) String() string            { return proto.CompactTextString(m) }
func (*QueryPlanStatusResponseProto) ProtoMessage()               {}
func (*QueryPlanStatusResponseProto) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{23} }

func (m *QueryPlanStatusResponseProto) GetResult() uint32 {
	if m != nil && m.Result != nil {
		return *m.Result
	}
	return 0
}

func (m *QueryPlanStatusResponseProto) GetPlanID() string {
	if m != nil && m.PlanID != nil {
		return *m.PlanID
	}
	return ""
}

func (m *QueryPlanStatusResponseProto) GetCurrentStatus() string {
	if m != nil && m.CurrentStatus != nil {
		return *m.CurrentStatus
	}
	return ""
}

// *
// This message sends a request to data node get a specific setting
// that is used by disk balancer.
type DiskBalancerSettingRequestProto struct {
	Key              *string `protobuf:"bytes,1,req,name=key" json:"key,omitempty"`
	XXX_unrecognized []byte  `json:"-"`
}

func (m *DiskBalancerSettingRequestProto) Reset()         { *m = DiskBalancerSettingRequestProto{} }
func (m *DiskBalancerSettingRequestProto) String() string { return proto.CompactTextString(m) }
func (*DiskBalancerSettingRequestProto) ProtoMessage()    {}
func (*DiskBalancerSettingRequestProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{24}
}

func (m *DiskBalancerSettingRequestProto) GetKey() string {
	if m != nil && m.Key != nil {
		return *m.Key
	}
	return ""
}

// *
// Response that describes the value of requested disk balancer setting.
type DiskBalancerSettingResponseProto struct {
	Value            *string `protobuf:"bytes,1,req,name=value" json:"value,omitempty"`
	XXX_unrecognized []byte  `json:"-"`
}

func (m *DiskBalancerSettingResponseProto) Reset()         { *m = DiskBalancerSettingResponseProto{} }
func (m *DiskBalancerSettingResponseProto) String() string { return proto.CompactTextString(m) }
func (*DiskBalancerSettingResponseProto) ProtoMessage()    {}
func (*DiskBalancerSettingResponseProto) Descriptor() ([]byte, []int) {
	return fileDescriptor0, []int{25}
}

func (m *DiskBalancerSettingResponseProto) GetValue() string {
	if m != nil && m.Value != nil {
		return *m.Value
	}
	return ""
}

func init() {
	proto.RegisterType((*GetReplicaVisibleLengthRequestProto)(nil), "hadoop.hdfs.GetReplicaVisibleLengthRequestProto")
	proto.RegisterType((*GetReplicaVisibleLengthResponseProto)(nil), "hadoop.hdfs.GetReplicaVisibleLengthResponseProto")
	proto.RegisterType((*RefreshNamenodesRequestProto)(nil), "hadoop.hdfs.RefreshNamenodesRequestProto")
	proto.RegisterType((*RefreshNamenodesResponseProto)(nil), "hadoop.hdfs.RefreshNamenodesResponseProto")
	proto.RegisterType((*DeleteBlockPoolRequestProto)(nil), "hadoop.hdfs.DeleteBlockPoolRequestProto")
	proto.RegisterType((*DeleteBlockPoolResponseProto)(nil), "hadoop.hdfs.DeleteBlockPoolResponseProto")
	proto.RegisterType((*GetBlockLocalPathInfoRequestProto)(nil), "hadoop.hdfs.GetBlockLocalPathInfoRequestProto")
	proto.RegisterType((*GetBlockLocalPathInfoResponseProto)(nil), "hadoop.hdfs.GetBlockLocalPathInfoResponseProto")
	proto.RegisterType((*ShutdownDatanodeRequestProto)(nil), "hadoop.hdfs.ShutdownDatanodeRequestProto")
	proto.RegisterType((*ShutdownDatanodeResponseProto)(nil), "hadoop.hdfs.ShutdownDatanodeResponseProto")
	proto.RegisterType((*EvictWritersRequestProto)(nil), "hadoop.hdfs.EvictWritersRequestProto")
	proto.RegisterType((*EvictWritersResponseProto)(nil), "hadoop.hdfs.EvictWritersResponseProto")
	proto.RegisterType((*GetDatanodeInfoRequestProto)(nil), "hadoop.hdfs.GetDatanodeInfoRequestProto")
	proto.RegisterType((*GetDatanodeInfoResponseProto)(nil), "hadoop.hdfs.GetDatanodeInfoResponseProto")
	proto.RegisterType((*TriggerBlockReportRequestProto)(nil), "hadoop.hdfs.TriggerBlockReportRequestProto")
	proto.RegisterType((*TriggerBlockReportResponseProto)(nil), "hadoop.hdfs.TriggerBlockReportResponseProto")
	proto.RegisterType((*GetBalancerBandwidthRequestProto)(nil), "hadoop.hdfs.GetBalancerBandwidthRequestProto")
	proto.RegisterType((*GetBalancerBandwidthResponseProto)(nil), "hadoop.hdfs.GetBalancerBandwidthResponseProto")
	proto.RegisterType((*SubmitDiskBalancerPlanRequestProto)(nil), "hadoop.hdfs.SubmitDiskBalancerPlanRequestProto")
	proto.RegisterType((*SubmitDiskBalancerPlanResponseProto)(nil), "hadoop.hdfs.SubmitDiskBalancerPlanResponseProto")
	proto.RegisterType((*CancelPlanRequestProto)(nil), "hadoop.hdfs.CancelPlanRequestProto")
	proto.RegisterType((*CancelPlanResponseProto)(nil), "hadoop.hdfs.CancelPlanResponseProto")
	proto.RegisterType((*QueryPlanStatusRequestProto)(nil), "hadoop.hdfs.QueryPlanStatusRequestProto")
	proto.RegisterType((*QueryPlanStatusResponseProto)(nil), "hadoop.hdfs.QueryPlanStatusResponseProto")
	proto.RegisterType((*DiskBalancerSettingRequestProto)(nil), "hadoop.hdfs.DiskBalancerSettingRequestProto")
	proto.RegisterType((*DiskBalancerSettingResponseProto)(nil), "hadoop.hdfs.DiskBalancerSettingResponseProto")
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion3

// Client API for ClientDatanodeProtocolService service

type ClientDatanodeProtocolServiceClient interface {
	// *
	// Returns the visible length of the replica
	GetReplicaVisibleLength(ctx context.Context, in *GetReplicaVisibleLengthRequestProto, opts ...grpc.CallOption) (*GetReplicaVisibleLengthResponseProto, error)
	// *
	// Refresh the list of federated namenodes from updated configuration.
	// Adds new namenodes and stops the deleted namenodes.
	RefreshNamenodes(ctx context.Context, in *RefreshNamenodesRequestProto, opts ...grpc.CallOption) (*RefreshNamenodesResponseProto, error)
	// *
	// Delete the block pool from the datanode.
	DeleteBlockPool(ctx context.Context, in *DeleteBlockPoolRequestProto, opts ...grpc.CallOption) (*DeleteBlockPoolResponseProto, error)
	// *
	// Retrieves the path names of the block file and metadata file stored on the
	// local file system.
	GetBlockLocalPathInfo(ctx context.Context, in *GetBlockLocalPathInfoRequestProto, opts ...grpc.CallOption) (*GetBlockLocalPathInfoResponseProto, error)
	ShutdownDatanode(ctx context.Context, in *ShutdownDatanodeRequestProto, opts ...grpc.CallOption) (*ShutdownDatanodeResponseProto, error)
	EvictWriters(ctx context.Context, in *EvictWritersRequestProto, opts ...grpc.CallOption) (*EvictWritersResponseProto, error)
	GetDatanodeInfo(ctx context.Context, in *GetDatanodeInfoRequestProto, opts ...grpc.CallOption) (*GetDatanodeInfoResponseProto, error)
	GetReconfigurationStatus(ctx context.Context, in *hadoop_hdfs1.GetReconfigurationStatusRequestProto, opts ...grpc.CallOption) (*hadoop_hdfs1.GetReconfigurationStatusResponseProto, error)
	StartReconfiguration(ctx context.Context, in *hadoop_hdfs1.StartReconfigurationRequestProto, opts ...grpc.CallOption) (*hadoop_hdfs1.StartReconfigurationResponseProto, error)
	ListReconfigurableProperties(ctx context.Context, in *hadoop_hdfs1.ListReconfigurablePropertiesRequestProto, opts ...grpc.CallOption) (*hadoop_hdfs1.ListReconfigurablePropertiesResponseProto, error)
	TriggerBlockReport(ctx context.Context, in *TriggerBlockReportRequestProto, opts ...grpc.CallOption) (*TriggerBlockReportResponseProto, error)
	// *
	// Returns the balancer bandwidth value of datanode.
	GetBalancerBandwidth(ctx context.Context, in *GetBalancerBandwidthRequestProto, opts ...grpc.CallOption) (*GetBalancerBandwidthResponseProto, error)
	// *
	// Submit a disk balancer plan for execution
	SubmitDiskBalancerPlan(ctx context.Context, in *SubmitDiskBalancerPlanRequestProto, opts ...grpc.CallOption) (*SubmitDiskBalancerPlanResponseProto, error)
	// *
	// Cancel an executing plan
	CancelDiskBalancerPlan(ctx context.Context, in *CancelPlanRequestProto, opts ...grpc.CallOption) (*CancelPlanResponseProto, error)
	// *
	// Gets the status of an executing Plan
	QueryDiskBalancerPlan(ctx context.Context, in *QueryPlanStatusRequestProto, opts ...grpc.CallOption) (*QueryPlanStatusResponseProto, error)
	// *
	//  Gets run-time settings of Disk Balancer.
	GetDiskBalancerSetting(ctx context.Context, in *DiskBalancerSettingRequestProto, opts ...grpc.CallOption) (*DiskBalancerSettingResponseProto, error)
}

type clientDatanodeProtocolServiceClient struct {
	cc *grpc.ClientConn
}

func NewClientDatanodeProtocolServiceClient(cc *grpc.ClientConn) ClientDatanodeProtocolServiceClient {
	return &clientDatanodeProtocolServiceClient{cc}
}

func (c *clientDatanodeProtocolServiceClient) GetReplicaVisibleLength(ctx context.Context, in *GetReplicaVisibleLengthRequestProto, opts ...grpc.CallOption) (*GetReplicaVisibleLengthResponseProto, error) {
	out := new(GetReplicaVisibleLengthResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/getReplicaVisibleLength", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) RefreshNamenodes(ctx context.Context, in *RefreshNamenodesRequestProto, opts ...grpc.CallOption) (*RefreshNamenodesResponseProto, error) {
	out := new(RefreshNamenodesResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/refreshNamenodes", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) DeleteBlockPool(ctx context.Context, in *DeleteBlockPoolRequestProto, opts ...grpc.CallOption) (*DeleteBlockPoolResponseProto, error) {
	out := new(DeleteBlockPoolResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/deleteBlockPool", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) GetBlockLocalPathInfo(ctx context.Context, in *GetBlockLocalPathInfoRequestProto, opts ...grpc.CallOption) (*GetBlockLocalPathInfoResponseProto, error) {
	out := new(GetBlockLocalPathInfoResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/getBlockLocalPathInfo", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) ShutdownDatanode(ctx context.Context, in *ShutdownDatanodeRequestProto, opts ...grpc.CallOption) (*ShutdownDatanodeResponseProto, error) {
	out := new(ShutdownDatanodeResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/shutdownDatanode", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) EvictWriters(ctx context.Context, in *EvictWritersRequestProto, opts ...grpc.CallOption) (*EvictWritersResponseProto, error) {
	out := new(EvictWritersResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/evictWriters", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) GetDatanodeInfo(ctx context.Context, in *GetDatanodeInfoRequestProto, opts ...grpc.CallOption) (*GetDatanodeInfoResponseProto, error) {
	out := new(GetDatanodeInfoResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/getDatanodeInfo", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) GetReconfigurationStatus(ctx context.Context, in *hadoop_hdfs1.GetReconfigurationStatusRequestProto, opts ...grpc.CallOption) (*hadoop_hdfs1.GetReconfigurationStatusResponseProto, error) {
	out := new(hadoop_hdfs1.GetReconfigurationStatusResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/getReconfigurationStatus", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) StartReconfiguration(ctx context.Context, in *hadoop_hdfs1.StartReconfigurationRequestProto, opts ...grpc.CallOption) (*hadoop_hdfs1.StartReconfigurationResponseProto, error) {
	out := new(hadoop_hdfs1.StartReconfigurationResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/startReconfiguration", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) ListReconfigurableProperties(ctx context.Context, in *hadoop_hdfs1.ListReconfigurablePropertiesRequestProto, opts ...grpc.CallOption) (*hadoop_hdfs1.ListReconfigurablePropertiesResponseProto, error) {
	out := new(hadoop_hdfs1.ListReconfigurablePropertiesResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/listReconfigurableProperties", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) TriggerBlockReport(ctx context.Context, in *TriggerBlockReportRequestProto, opts ...grpc.CallOption) (*TriggerBlockReportResponseProto, error) {
	out := new(TriggerBlockReportResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/triggerBlockReport", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) GetBalancerBandwidth(ctx context.Context, in *GetBalancerBandwidthRequestProto, opts ...grpc.CallOption) (*GetBalancerBandwidthResponseProto, error) {
	out := new(GetBalancerBandwidthResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/getBalancerBandwidth", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) SubmitDiskBalancerPlan(ctx context.Context, in *SubmitDiskBalancerPlanRequestProto, opts ...grpc.CallOption) (*SubmitDiskBalancerPlanResponseProto, error) {
	out := new(SubmitDiskBalancerPlanResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/submitDiskBalancerPlan", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) CancelDiskBalancerPlan(ctx context.Context, in *CancelPlanRequestProto, opts ...grpc.CallOption) (*CancelPlanResponseProto, error) {
	out := new(CancelPlanResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/cancelDiskBalancerPlan", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) QueryDiskBalancerPlan(ctx context.Context, in *QueryPlanStatusRequestProto, opts ...grpc.CallOption) (*QueryPlanStatusResponseProto, error) {
	out := new(QueryPlanStatusResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/queryDiskBalancerPlan", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *clientDatanodeProtocolServiceClient) GetDiskBalancerSetting(ctx context.Context, in *DiskBalancerSettingRequestProto, opts ...grpc.CallOption) (*DiskBalancerSettingResponseProto, error) {
	out := new(DiskBalancerSettingResponseProto)
	err := grpc.Invoke(ctx, "/hadoop.hdfs.ClientDatanodeProtocolService/getDiskBalancerSetting", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// Server API for ClientDatanodeProtocolService service

type ClientDatanodeProtocolServiceServer interface {
	// *
	// Returns the visible length of the replica
	GetReplicaVisibleLength(context.Context, *GetReplicaVisibleLengthRequestProto) (*GetReplicaVisibleLengthResponseProto, error)
	// *
	// Refresh the list of federated namenodes from updated configuration.
	// Adds new namenodes and stops the deleted namenodes.
	RefreshNamenodes(context.Context, *RefreshNamenodesRequestProto) (*RefreshNamenodesResponseProto, error)
	// *
	// Delete the block pool from the datanode.
	DeleteBlockPool(context.Context, *DeleteBlockPoolRequestProto) (*DeleteBlockPoolResponseProto, error)
	// *
	// Retrieves the path names of the block file and metadata file stored on the
	// local file system.
	GetBlockLocalPathInfo(context.Context, *GetBlockLocalPathInfoRequestProto) (*GetBlockLocalPathInfoResponseProto, error)
	ShutdownDatanode(context.Context, *ShutdownDatanodeRequestProto) (*ShutdownDatanodeResponseProto, error)
	EvictWriters(context.Context, *EvictWritersRequestProto) (*EvictWritersResponseProto, error)
	GetDatanodeInfo(context.Context, *GetDatanodeInfoRequestProto) (*GetDatanodeInfoResponseProto, error)
	GetReconfigurationStatus(context.Context, *hadoop_hdfs1.GetReconfigurationStatusRequestProto) (*hadoop_hdfs1.GetReconfigurationStatusResponseProto, error)
	StartReconfiguration(context.Context, *hadoop_hdfs1.StartReconfigurationRequestProto) (*hadoop_hdfs1.StartReconfigurationResponseProto, error)
	ListReconfigurableProperties(context.Context, *hadoop_hdfs1.ListReconfigurablePropertiesRequestProto) (*hadoop_hdfs1.ListReconfigurablePropertiesResponseProto, error)
	TriggerBlockReport(context.Context, *TriggerBlockReportRequestProto) (*TriggerBlockReportResponseProto, error)
	// *
	// Returns the balancer bandwidth value of datanode.
	GetBalancerBandwidth(context.Context, *GetBalancerBandwidthRequestProto) (*GetBalancerBandwidthResponseProto, error)
	// *
	// Submit a disk balancer plan for execution
	SubmitDiskBalancerPlan(context.Context, *SubmitDiskBalancerPlanRequestProto) (*SubmitDiskBalancerPlanResponseProto, error)
	// *
	// Cancel an executing plan
	CancelDiskBalancerPlan(context.Context, *CancelPlanRequestProto) (*CancelPlanResponseProto, error)
	// *
	// Gets the status of an executing Plan
	QueryDiskBalancerPlan(context.Context, *QueryPlanStatusRequestProto) (*QueryPlanStatusResponseProto, error)
	// *
	//  Gets run-time settings of Disk Balancer.
	GetDiskBalancerSetting(context.Context, *DiskBalancerSettingRequestProto) (*DiskBalancerSettingResponseProto, error)
}

func RegisterClientDatanodeProtocolServiceServer(s *grpc.Server, srv ClientDatanodeProtocolServiceServer) {
	s.RegisterService(&_ClientDatanodeProtocolService_serviceDesc, srv)
}

func _ClientDatanodeProtocolService_GetReplicaVisibleLength_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetReplicaVisibleLengthRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).GetReplicaVisibleLength(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/GetReplicaVisibleLength",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).GetReplicaVisibleLength(ctx, req.(*GetReplicaVisibleLengthRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_RefreshNamenodes_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(RefreshNamenodesRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).RefreshNamenodes(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/RefreshNamenodes",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).RefreshNamenodes(ctx, req.(*RefreshNamenodesRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_DeleteBlockPool_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(DeleteBlockPoolRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).DeleteBlockPool(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/DeleteBlockPool",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).DeleteBlockPool(ctx, req.(*DeleteBlockPoolRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_GetBlockLocalPathInfo_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetBlockLocalPathInfoRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).GetBlockLocalPathInfo(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/GetBlockLocalPathInfo",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).GetBlockLocalPathInfo(ctx, req.(*GetBlockLocalPathInfoRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_ShutdownDatanode_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ShutdownDatanodeRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).ShutdownDatanode(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/ShutdownDatanode",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).ShutdownDatanode(ctx, req.(*ShutdownDatanodeRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_EvictWriters_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(EvictWritersRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).EvictWriters(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/EvictWriters",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).EvictWriters(ctx, req.(*EvictWritersRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_GetDatanodeInfo_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetDatanodeInfoRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).GetDatanodeInfo(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/GetDatanodeInfo",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).GetDatanodeInfo(ctx, req.(*GetDatanodeInfoRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_GetReconfigurationStatus_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(hadoop_hdfs1.GetReconfigurationStatusRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).GetReconfigurationStatus(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/GetReconfigurationStatus",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).GetReconfigurationStatus(ctx, req.(*hadoop_hdfs1.GetReconfigurationStatusRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_StartReconfiguration_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(hadoop_hdfs1.StartReconfigurationRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).StartReconfiguration(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/StartReconfiguration",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).StartReconfiguration(ctx, req.(*hadoop_hdfs1.StartReconfigurationRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_ListReconfigurableProperties_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(hadoop_hdfs1.ListReconfigurablePropertiesRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).ListReconfigurableProperties(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/ListReconfigurableProperties",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).ListReconfigurableProperties(ctx, req.(*hadoop_hdfs1.ListReconfigurablePropertiesRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_TriggerBlockReport_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(TriggerBlockReportRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).TriggerBlockReport(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/TriggerBlockReport",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).TriggerBlockReport(ctx, req.(*TriggerBlockReportRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_GetBalancerBandwidth_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetBalancerBandwidthRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).GetBalancerBandwidth(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/GetBalancerBandwidth",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).GetBalancerBandwidth(ctx, req.(*GetBalancerBandwidthRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_SubmitDiskBalancerPlan_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SubmitDiskBalancerPlanRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).SubmitDiskBalancerPlan(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/SubmitDiskBalancerPlan",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).SubmitDiskBalancerPlan(ctx, req.(*SubmitDiskBalancerPlanRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_CancelDiskBalancerPlan_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CancelPlanRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).CancelDiskBalancerPlan(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/CancelDiskBalancerPlan",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).CancelDiskBalancerPlan(ctx, req.(*CancelPlanRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_QueryDiskBalancerPlan_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(QueryPlanStatusRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).QueryDiskBalancerPlan(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/QueryDiskBalancerPlan",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).QueryDiskBalancerPlan(ctx, req.(*QueryPlanStatusRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

func _ClientDatanodeProtocolService_GetDiskBalancerSetting_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(DiskBalancerSettingRequestProto)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(ClientDatanodeProtocolServiceServer).GetDiskBalancerSetting(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/hadoop.hdfs.ClientDatanodeProtocolService/GetDiskBalancerSetting",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(ClientDatanodeProtocolServiceServer).GetDiskBalancerSetting(ctx, req.(*DiskBalancerSettingRequestProto))
	}
	return interceptor(ctx, in, info, handler)
}

var _ClientDatanodeProtocolService_serviceDesc = grpc.ServiceDesc{
	ServiceName: "hadoop.hdfs.ClientDatanodeProtocolService",
	HandlerType: (*ClientDatanodeProtocolServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "getReplicaVisibleLength",
			Handler:    _ClientDatanodeProtocolService_GetReplicaVisibleLength_Handler,
		},
		{
			MethodName: "refreshNamenodes",
			Handler:    _ClientDatanodeProtocolService_RefreshNamenodes_Handler,
		},
		{
			MethodName: "deleteBlockPool",
			Handler:    _ClientDatanodeProtocolService_DeleteBlockPool_Handler,
		},
		{
			MethodName: "getBlockLocalPathInfo",
			Handler:    _ClientDatanodeProtocolService_GetBlockLocalPathInfo_Handler,
		},
		{
			MethodName: "shutdownDatanode",
			Handler:    _ClientDatanodeProtocolService_ShutdownDatanode_Handler,
		},
		{
			MethodName: "evictWriters",
			Handler:    _ClientDatanodeProtocolService_EvictWriters_Handler,
		},
		{
			MethodName: "getDatanodeInfo",
			Handler:    _ClientDatanodeProtocolService_GetDatanodeInfo_Handler,
		},
		{
			MethodName: "getReconfigurationStatus",
			Handler:    _ClientDatanodeProtocolService_GetReconfigurationStatus_Handler,
		},
		{
			MethodName: "startReconfiguration",
			Handler:    _ClientDatanodeProtocolService_StartReconfiguration_Handler,
		},
		{
			MethodName: "listReconfigurableProperties",
			Handler:    _ClientDatanodeProtocolService_ListReconfigurableProperties_Handler,
		},
		{
			MethodName: "triggerBlockReport",
			Handler:    _ClientDatanodeProtocolService_TriggerBlockReport_Handler,
		},
		{
			MethodName: "getBalancerBandwidth",
			Handler:    _ClientDatanodeProtocolService_GetBalancerBandwidth_Handler,
		},
		{
			MethodName: "submitDiskBalancerPlan",
			Handler:    _ClientDatanodeProtocolService_SubmitDiskBalancerPlan_Handler,
		},
		{
			MethodName: "cancelDiskBalancerPlan",
			Handler:    _ClientDatanodeProtocolService_CancelDiskBalancerPlan_Handler,
		},
		{
			MethodName: "queryDiskBalancerPlan",
			Handler:    _ClientDatanodeProtocolService_QueryDiskBalancerPlan_Handler,
		},
		{
			MethodName: "getDiskBalancerSetting",
			Handler:    _ClientDatanodeProtocolService_GetDiskBalancerSetting_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: fileDescriptor0,
}

func init() { proto.RegisterFile("ClientDatanodeProtocol.proto", fileDescriptor0) }

var fileDescriptor0 = []byte{
	// 1069 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x09, 0x6e, 0x88, 0x02, 0xff, 0xac, 0x57, 0xdd, 0x6e, 0xdc, 0x44,
	0x14, 0x96, 0xdb, 0x04, 0xa5, 0x27, 0xf4, 0x47, 0xa3, 0x76, 0x9b, 0x38, 0x9b, 0x9f, 0x3a, 0x09,
	0x4a, 0x81, 0x6e, 0x43, 0x50, 0x11, 0x57, 0x48, 0x4d, 0x52, 0xa1, 0x8a, 0x80, 0x52, 0x6f, 0x29,
	0x37, 0x70, 0x31, 0xb1, 0xcf, 0x7a, 0xad, 0x38, 0x9e, 0xed, 0x78, 0xdc, 0x36, 0x42, 0x42, 0xe2,
	0x0e, 0x09, 0xf1, 0x06, 0x48, 0xf0, 0x58, 0x3c, 0x0e, 0x33, 0x63, 0x9b, 0xcc, 0xd8, 0x5e, 0xef,
	0x82, 0xb8, 0xb2, 0x3d, 0xe7, 0x3b, 0x3f, 0xf3, 0xcd, 0x39, 0xf3, 0xed, 0x42, 0xff, 0x28, 0x89,
	0x31, 0x15, 0xc7, 0x54, 0xd0, 0x94, 0x85, 0x78, 0xca, 0x99, 0x60, 0x01, 0x4b, 0x06, 0x13, 0xf5,
	0x42, 0x96, 0xc7, 0x34, 0x64, 0x6c, 0x32, 0x18, 0x87, 0xa3, 0xcc, 0xbd, 0x35, 0xc4, 0x20, 0xe7,
	0xb1, 0xb8, 0x2c, 0x8c, 0x2e, 0xa8, 0xd5, 0xf2, 0x7d, 0xdd, 0xc7, 0x80, 0xa5, 0xa3, 0x38, 0xca,
	0x39, 0x15, 0x31, 0x4b, 0xed, 0x38, 0xde, 0xf7, 0xb0, 0xfd, 0x25, 0x0a, 0x1f, 0x27, 0x49, 0x1c,
	0xd0, 0x57, 0x71, 0x16, 0x9f, 0x25, 0x78, 0x82, 0x69, 0x24, 0xc6, 0x3e, 0xbe, 0xce, 0x31, 0x13,
	0x1a, 0x4f, 0x9e, 0xc0, 0xe2, 0x59, 0xc2, 0x82, 0xf3, 0x15, 0x67, 0xeb, 0xda, 0xde, 0xf2, 0xc1,
	0xe6, 0xc0, 0x48, 0x3f, 0x78, 0xf6, 0x4e, 0x60, 0x1a, 0x62, 0x78, 0xa8, 0x10, 0x1a, 0xef, 0x17,
	0x68, 0xef, 0x0b, 0xd8, 0x99, 0x1a, 0x3d, 0x9b, 0xb0, 0x34, 0x2b, 0xb6, 0x45, 0x7a, 0xf0, 0x5e,
	0xa2, 0x97, 0x75, 0xfc, 0x05, 0xbf, 0xfc, 0xf2, 0x36, 0xa0, 0xef, 0xe3, 0x88, 0x63, 0x36, 0xfe,
	0x86, 0x5e, 0xa0, 0xa2, 0x21, 0x33, 0xcb, 0xf2, 0x36, 0x61, 0xbd, 0x69, 0x37, 0x02, 0x7b, 0x2f,
	0x60, 0xed, 0x18, 0x13, 0x14, 0x58, 0xd4, 0xc6, 0x58, 0x62, 0x6d, 0xab, 0x0f, 0x37, 0xce, 0x2a,
	0x83, 0x4e, 0x7d, 0xc3, 0xbf, 0x5a, 0x20, 0x77, 0x61, 0x71, 0xc4, 0x78, 0x80, 0x2b, 0xd7, 0xa4,
	0x65, 0xc9, 0x2f, 0x3e, 0x54, 0x4d, 0x8d, 0x90, 0x66, 0xca, 0x5f, 0x1d, 0x78, 0x20, 0x37, 0xad,
	0xad, 0x27, 0x2c, 0xa0, 0xc9, 0x29, 0x15, 0xe3, 0xe7, 0xe9, 0x88, 0xfd, 0x0f, 0x84, 0x92, 0xc7,
	0xb0, 0x28, 0xd8, 0x39, 0xa6, 0xba, 0xa4, 0xe5, 0x83, 0xd5, 0xca, 0x2d, 0x60, 0x17, 0x17, 0x2c,
	0x1d, 0xbc, 0x54, 0xb6, 0xd2, 0x41, 0xe3, 0xbc, 0x3f, 0x1c, 0xf0, 0xa6, 0x54, 0x63, 0x1e, 0xc0,
	0x7f, 0x2c, 0x47, 0xf2, 0x97, 0x54, 0x41, 0x75, 0x49, 0x92, 0xbf, 0x7f, 0x16, 0xc8, 0x0e, 0xdc,
	0xd4, 0x1f, 0x5f, 0xa3, 0xa0, 0x1a, 0x71, 0x5d, 0x23, 0xec, 0x45, 0xd9, 0x23, 0xfd, 0xe1, 0x38,
	0x17, 0x21, 0x7b, 0x9b, 0x56, 0xbd, 0x6e, 0x31, 0xb5, 0x01, 0x20, 0x89, 0xff, 0x76, 0x12, 0x71,
	0x1a, 0xa2, 0xae, 0x6f, 0xc9, 0x37, 0x56, 0x54, 0x0f, 0x34, 0xfd, 0xcd, 0x03, 0x71, 0x61, 0xe5,
	0xd9, 0x9b, 0x38, 0x10, 0xdf, 0xc9, 0x09, 0x41, 0x6e, 0x37, 0xd0, 0x1a, 0xac, 0xda, 0x36, 0xd3,
	0x71, 0x1d, 0xd6, 0x24, 0x75, 0x55, 0xd0, 0xfa, 0x11, 0x7a, 0x14, 0xfa, 0x0d, 0xb3, 0xc9, 0xe9,
	0xd3, 0x92, 0x1c, 0x65, 0x29, 0x79, 0xdd, 0xb6, 0x78, 0xad, 0x5c, 0x4f, 0x2a, 0x54, 0xc1, 0xed,
	0x95, 0x97, 0x77, 0x08, 0x1b, 0x2f, 0x79, 0x1c, 0x45, 0xc8, 0x35, 0xf7, 0x72, 0x90, 0x18, 0x17,
	0x16, 0x3b, 0x5b, 0xb0, 0x1c, 0xa7, 0x01, 0x47, 0xd9, 0xfd, 0x82, 0x26, 0x25, 0x3d, 0xe6, 0x92,
	0xf7, 0x00, 0x36, 0xdb, 0x62, 0x98, 0x1b, 0xf5, 0x60, 0x4b, 0xf5, 0x08, 0x4d, 0x68, 0x1a, 0x48,
	0x18, 0x4d, 0xc3, 0xb7, 0x71, 0x68, 0xdf, 0x00, 0xde, 0xd3, 0xa2, 0xab, 0x9b, 0x18, 0x73, 0xcb,
	0x6a, 0x9e, 0x2a, 0x4b, 0x39, 0xca, 0x57, 0x0b, 0xde, 0xef, 0xb2, 0x17, 0x87, 0xf9, 0xd9, 0x45,
	0x2c, 0x8e, 0xe3, 0xec, 0xbc, 0x0a, 0x75, 0x2a, 0x1f, 0xd6, 0x96, 0xe4, 0x65, 0x30, 0x91, 0x6b,
	0xcf, 0x8f, 0xcb, 0x89, 0x2c, 0xbf, 0x08, 0x81, 0x05, 0xf5, 0x56, 0xf6, 0x99, 0x7e, 0x57, 0xdb,
	0x57, 0xcf, 0x57, 0xf2, 0xec, 0xe4, 0xdd, 0x26, 0x1b, 0xcc, 0x91, 0x29, 0xcd, 0x25, 0xb2, 0x07,
	0xb7, 0xe3, 0x28, 0x65, 0x1c, 0x25, 0xdb, 0x78, 0x34, 0x46, 0xd9, 0xe3, 0x0b, 0x12, 0xb5, 0xe4,
	0xd7, 0x97, 0xbd, 0x5d, 0xd8, 0x9e, 0x56, 0x9d, 0x49, 0xd6, 0x3e, 0xf4, 0x8e, 0x94, 0x29, 0x99,
	0xb7, 0x70, 0x6f, 0x15, 0xee, 0x9b, 0x1e, 0xb5, 0x16, 0x7b, 0x91, 0x23, 0xbf, 0x54, 0x96, 0xa1,
	0xa0, 0x22, 0xb7, 0xdb, 0x53, 0x40, 0xbf, 0x61, 0xae, 0xdd, 0x9b, 0xf2, 0xf2, 0xcb, 0x13, 0x21,
	0x33, 0x3a, 0x7b, 0x37, 0xfd, 0xf2, 0xcb, 0xa8, 0xe4, 0x9a, 0x5c, 0xbf, 0xa2, 0x50, 0x4e, 0xa4,
	0x14, 0x0a, 0x2e, 0x1b, 0xa3, 0x88, 0xa6, 0x09, 0x93, 0x13, 0x69, 0x2d, 0x7a, 0x9f, 0xc2, 0xa6,
	0x49, 0xc1, 0x10, 0x85, 0x88, 0xd3, 0xc8, 0xda, 0xea, 0x1d, 0xb8, 0x7e, 0x8e, 0x97, 0xe5, 0x3e,
	0xd5, 0xab, 0xf7, 0x39, 0x6c, 0xb5, 0x3a, 0x99, 0xe5, 0xca, 0x0b, 0xf5, 0x0d, 0x4d, 0x72, 0x2c,
	0xfd, 0x8a, 0x8f, 0x83, 0xbf, 0x6e, 0xc1, 0x7a, 0xbb, 0xd6, 0x0d, 0x91, 0xcb, 0xe1, 0x44, 0xf2,
	0x13, 0xdc, 0x8f, 0xda, 0x65, 0x84, 0xec, 0x5b, 0x13, 0x35, 0x87, 0x94, 0xb9, 0x9f, 0xcc, 0xe7,
	0x61, 0xd6, 0x1d, 0xc3, 0x1d, 0x5e, 0x93, 0x19, 0xf2, 0xd0, 0x0a, 0xd3, 0xa5, 0x52, 0xee, 0x87,
	0x33, 0xa0, 0x66, 0xaa, 0x11, 0xdc, 0x0e, 0x6d, 0x75, 0x21, 0x7b, 0xf6, 0xa5, 0x31, 0x5d, 0xce,
	0xdc, 0x87, 0xdd, 0x48, 0x33, 0xcf, 0x3b, 0xb8, 0x17, 0xb5, 0xc9, 0x02, 0x19, 0xd4, 0xe9, 0xe9,
	0x16, 0x32, 0xf7, 0xf1, 0x3c, 0xf8, 0x1a, 0x99, 0x59, 0xed, 0xbe, 0xae, 0x91, 0xd9, 0x25, 0x07,
	0x35, 0x32, 0x3b, 0x6f, 0x7e, 0xf2, 0x03, 0xbc, 0x8f, 0xc6, 0xed, 0x4e, 0x76, 0x6d, 0x59, 0x9b,
	0x22, 0x0a, 0xee, 0x07, 0x1d, 0xb0, 0xda, 0x59, 0x45, 0xb6, 0x00, 0xd4, 0xce, 0xaa, 0x43, 0x3d,
	0x6a, 0x67, 0xd5, 0x29, 0x24, 0x3f, 0x3b, 0xb0, 0xa2, 0xfb, 0xdf, 0xfa, 0x21, 0x57, 0x0c, 0x2b,
	0x69, 0x69, 0xe7, 0x16, 0x98, 0x95, 0xfa, 0x60, 0x4e, 0x17, 0xb3, 0x86, 0x1c, 0xee, 0x66, 0x82,
	0xf2, 0x3a, 0x94, 0x3c, 0xb2, 0x8f, 0xa3, 0x05, 0x62, 0xa5, 0x1e, 0xcc, 0x01, 0x37, 0xd3, 0xfe,
	0xe6, 0x40, 0x3f, 0x89, 0x33, 0x13, 0x24, 0x67, 0x54, 0xda, 0x26, 0xc8, 0x45, 0x2c, 0xc7, 0xf0,
	0x89, 0x15, 0xf0, 0xa4, 0x03, 0x6a, 0xd5, 0xf1, 0xd9, 0xbf, 0x70, 0x33, 0xeb, 0x61, 0x40, 0x44,
	0x43, 0x4c, 0xc9, 0x47, 0x56, 0xb4, 0x6e, 0xc5, 0x76, 0x3f, 0x9e, 0x09, 0xae, 0xf1, 0x1e, 0xb5,
	0xc8, 0x6e, 0x8d, 0xf7, 0x59, 0xea, 0xed, 0x0e, 0xe6, 0x80, 0x9b, 0x69, 0x7f, 0x84, 0x5e, 0xd6,
	0xaa, 0x85, 0xc4, 0x9e, 0xf7, 0xd9, 0x72, 0xee, 0xee, 0xcf, 0xe5, 0x60, 0x26, 0x0f, 0xa0, 0x17,
	0x68, 0xbd, 0x6c, 0x24, 0xb7, 0x7f, 0x3f, 0xb5, 0xcb, 0xb0, 0xbb, 0x33, 0x15, 0x64, 0x26, 0x49,
	0xe0, 0xde, 0x6b, 0x25, 0xad, 0x8d, 0x1c, 0xf6, 0x08, 0x77, 0xa8, 0x73, 0x6d, 0x84, 0x3b, 0x85,
	0x3a, 0x87, 0x9e, 0xba, 0x2a, 0x9a, 0x02, 0x49, 0xec, 0x76, 0x98, 0xa1, 0xbb, 0xee, 0xa3, 0xd9,
	0x68, 0x23, 0xed, 0xe1, 0x57, 0xb0, 0xcb, 0x78, 0x34, 0xa0, 0x13, 0x1a, 0x8c, 0xd1, 0x72, 0x9d,
	0x58, 0x7f, 0x03, 0x0f, 0xa7, 0xfc, 0xd9, 0xd4, 0xcf, 0xec, 0x17, 0xc7, 0xf9, 0xd3, 0x71, 0xfe,
	0x0e, 0x00, 0x00, 0xff, 0xff, 0x0b, 0x31, 0xce, 0x8a, 0x91, 0x0e, 0x00, 0x00,
}
